{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019-09-28\n",
    "\n",
    "1. 클래스\n",
    "2. 정규표현식 --> pandas\n",
    "3. HTML 분석\n",
    "4. 크롤링\n",
    "\n",
    "***\n",
    "\n",
    "### - HTML(Hyper Text Markup Language)\n",
    "+ 링크로 연결된 텍스트 페이지  \n",
    "+ 자유롭게 이동이 가능하다.  \n",
    "+ 웹페이지를 구성한다. -> HTML(뼈대), CSS(옷), Javasript(특수기능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1=스크레이핑이란?\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# 분석하고 싶은 HTML 코드\n",
    "html1= '''\n",
    "<html>\n",
    "    <body>\n",
    "        <h1>스크레이핑이란?</h1>\n",
    "        <p>웹 페이지를 분석하는 것</p>\n",
    "        <p>원하는 부분을 추출하는 것</p>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "html2 = 'C://Users/dazzul/Documents/GitHub/python_basic/20190928/bs4.html'\n",
    "\n",
    "# HTML 분석하기\n",
    "soup = BeautifulSoup(open(html2,encoding='utf8'), 'html.parser', )\n",
    "\n",
    "# 원하는 부분 선택하여 출력하기\n",
    "h1 = soup.html.body.h1\n",
    "\n",
    "#선택된요소에서 글자 추출\n",
    "print(\"h1=\"+h1.string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 첫번째 p태그 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1=스크레이핑이란?\n",
      "p1=웹 페이지를 분석하는 것\n",
      "p2=원하는 부분을 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# 분석하고 싶은 HTML 코드\n",
    "html1= '''\n",
    "<html>\n",
    "    <body>\n",
    "        <h1>스크레이핑이란?</h1>\n",
    "        <p>웹 페이지를 분석하는 것</p>\n",
    "        <p>원하는 부분을 추출하는 것</p>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "html2 = 'C://Users/dazzul/Documents/GitHub/python_basic/20190928/bs4.html'\n",
    "\n",
    "# HTML 분석하기\n",
    "soup = BeautifulSoup(open(html2,encoding='utf8'), 'html.parser', )\n",
    "\n",
    "# 원하는 부분 선택하여 출력하기\n",
    "h1 = soup.html.body.h1\n",
    "p1 = soup.html.body.p\n",
    "p2 = p1.next_sibling.next_sibling\n",
    "\n",
    "#선택된요소에서 글자 추출\n",
    "print(\"h1=\"+h1.string)\n",
    "print(\"p1=\"+p1.string)\n",
    "print(\"p2=\"+p2.string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id로 찾기(find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title=스크레이핑이란?\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# 분석하고 싶은 HTML 코드\n",
    "html= '''\n",
    "<html>\n",
    "    <body>\n",
    "        <h1 id=\"title\">스크레이핑이란?</h1>\n",
    "        <p>웹 페이지를 분석하는 것</p>\n",
    "        <p>원하는 부분을 추출하는 것</p>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "# HTML 분석하기\n",
    "soup = BeautifulSoup(html, 'html.parser', )\n",
    "\n",
    "# 원하는 부분 선택하여 출력하기\n",
    "title = soup.find(id=\"title\")\n",
    "\n",
    "#선택된요소에서 글자 추출\n",
    "print(\"title=\"+title.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기상청 예보 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기상청 육상 중기예보\n",
      "기압골과 동풍의 영향으로 10월 1일과 2일은 강원영동과 남부지방, 제주도에 비가 오겠고, 강원영동과 경상도는 3일까지 이어지는 곳이 있겠습니다.<br />한편, 동풍의 영향으로 5일 강원영동에는 비가 오겠습니다. 그 밖의 날은 고기압의 가장자리에 들어 구름많겠습니다.<br />기온은 평년(최저기온: 7~17℃, 최고기온: 21~25℃)보다 조금 높겠습니다.<br />강수량은 평년(1~6mm)보다 중부지방(강원영동 제외)은 적겠으나, 강원영동과 남부지방, 제주도는 많겠습니다.<br /><br />* 괌 서쪽해상에 위치한 열대저압부의 발달과 이동경로에 따라 10월 1일 이후의 예보 변동성이 크겠으니, 앞으로 발표되는 예보와 기상정보를 참고하기 바랍니다.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "url = 'http://www.weather.go.kr/weather/forecast/mid-term-rss3.jsp'\n",
    "\n",
    "res = req.urlopen(url)\n",
    "\n",
    "soup = BeautifulSoup(res, 'html.parser')\n",
    "\n",
    "title = soup.find(\"title\").string\n",
    "wf = soup.find(\"wf\").string\n",
    "print(title)\n",
    "print(wf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <li> 리스트 뽑기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "좋아하는 영화\n",
      "너무\n",
      "돈을\n",
      "쉽게\n",
      "버시네\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        <div id=\"meigen\">\n",
    "        <h1>좋아하는 영화</h1>\n",
    "        <ul class=\"items\">\n",
    "            <li>너무</li>\n",
    "            <li>돈을</li>\n",
    "            <li>쉽게</li>\n",
    "            <li>버시네</li>\n",
    "        </ul>\n",
    "        </div>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "h1 = soup.select_one(\"div#meigen>h1\").string\n",
    "print(h1)\n",
    "\n",
    "li_list = soup.select(\"div#meigen>ul.items>li\")\n",
    "for li in li_list:\n",
    "    print(li.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네이버 금융에서 환율 정보 추측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,200.00\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "url = \"https://finance.naver.com/marketindex/\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "soup = BeautifulSoup(res, 'html.parser')\n",
    "\n",
    "price = soup.select_one(\"#exchangeList > li.on > a.head.usd > div > span.value\").string\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,200.00\n",
      "1,110.03\n",
      "1,312.44\n",
      "168.51\n",
      "108.1400\n",
      "1.0947\n",
      "1.2313\n",
      "98.7600\n",
      "55.91\n",
      "1542.1\n",
      "1499.1\n",
      "57711.71\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "url = \"https://finance.naver.com/marketindex/\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "soup = BeautifulSoup(res, 'html.parser')\n",
    "\n",
    "prices = soup.select(\"span.value\")\n",
    "for price in prices:\n",
    "    print(price.string)\n",
    "\n",
    "# print(\"달러 = \", price[0].string + \"원입니다\")\n",
    "# print(\"엔화 = \", price[1].string + \"원입니다\")\n",
    "# print(\"유로화 = \", price[2].string + \"원입니다\")\n",
    "# print(\"위엔화\", price[3].string + \"원입니다\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네이버 뉴스 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "♨ 헤드라인 뉴스\n",
      "中 왕이, 유엔서 “대북 제제 철회해야”…北 비핵화 ‘단계적·동시적’ 해법 주장\n",
      "법원 “이재명에 ‘거머리’ 표현 사용은 인신공격…변희재 배상해야”\n",
      "윤석열 코앞서 “수호”vs“사퇴” 오늘 ‘조국’ 대규모 집회\n",
      "5살 때려 숨지게 한 계부, 집행유예 기간에 또 범행\n",
      "강경화 \"미북 실무협상, 수주내 재개 예상\"\n",
      "--------------------------------------------------------------------------------------------\n",
      "♨ 정치\n",
      "이낙연 \"돼지열병 방역에 세계 최고 전문가 식견 총동원\"\n",
      "한국당, 曺·靑·與 맹공…\"검찰수사, 정의 세우라는 국민 명령\"\n",
      "추석 이후 원점. 총선 진검승부는 지금부터\n",
      "하태경 \"누명 씌운건 내가 아닌 문준용…조국처럼 살지 맙시다\"\n",
      "\"北 단거리발사체 발사 '9·19합의 위반'이라 하면 우리도 위반\"\n",
      "--------------------------------------------------------------------------------------------\n",
      "♨ 경제\n",
      "이낙연 총리 “강화, 바이러스 거의 창궐 직전…새로운 방역태세 갖출 필요”\n",
      "[김영필의 3분 월스트리트] 트럼프 탄핵이냐 워런 당선이냐···美 증시 누가 더 핵폭탄일까\n",
      "'배터리 싸움' 격화…LG화학, 미국서 SK이노 맞제소\n",
      "[단독] 규정 무시하고…자격 미달 업체 면세점 입점\n",
      "인보사·신라젠 이번엔 헬릭스미스…위기의 바이오주\n",
      "--------------------------------------------------------------------------------------------\n",
      "♨ 사회\n",
      "검찰 “법 절차 따라 엄정 수사…조국 통화 본질은 수사 압력”\n",
      "인천 고속도로서 차량 추돌 1명 숨져…아시아나 여객기 회항\n",
      "5살아들 때려죽인 20대 계부…지난해 집행유예로 풀려났다\n",
      "[똑똑팩톡] 이젠 범죄자 DNA 채취 못 한다고??\n",
      "정오부터 이동중지명령 해제...강화 돼지 살처분\n",
      "--------------------------------------------------------------------------------------------\n",
      "♨ 생활/문화\n",
      "중부 오후 한때 빗방울…남부 비 이어져\n",
      "르노삼성차, 희망퇴직 마감…생산 구조조정 준비\n",
      "주말 중부 늦더위·남부 비…10월에 태풍 또 오나\n",
      "노화하는 혈관 살리는 생활습관 3가지\n",
      "곽경택 감독 \"한국전쟁 영화 '장사리', 반공보단 반전 새겼죠\"\n",
      "--------------------------------------------------------------------------------------------\n",
      "♨ 세계\n",
      "홍콩·대만·위구르 건드리는 美, 발끈하는 中\n",
      "플라스틱 병으로 만든 튤립정원…재활용의 힘\n",
      "中 왕이, 유엔서 “대북 제제 철회해야”…北 비핵화 ‘단계적·동시적’ 해법 주장\n",
      "美 \"전자담배 의심 폐질환↑…지난주 13명 사망\"\n",
      "‘기형 닭’ 유통한 英 프랜차이즈 영상 충격…한국은 괜찮을까?\n",
      "--------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# %%writefile C:/Users/dazzul/Documents/GitHub/python_basic/20190928/aa.py\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "url = \"https://news.naver.com/\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "soup = BeautifulSoup(res, 'html.parser')\n",
    "# #today_main_news > div.hdline_news > ul > li:nth-child(1) > div.hdline_article_tit > a\n",
    "\n",
    "print(\"♨ 헤드라인 뉴스\")\n",
    "a_links = soup.select('#today_main_news > div.hdline_news > ul > li > div.hdline_article_tit > a')\n",
    "\n",
    "for a_link in a_links:\n",
    "    name = a_link.string\n",
    "    print(name.strip())\n",
    "    \n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"♨ 정치\")\n",
    "\n",
    "a_links = soup.select('#section_politics > div.com_list > div > ul > li > a > strong')\n",
    "\n",
    "for a_link in a_links:\n",
    "    name = a_link.string\n",
    "    print(name.strip())\n",
    "    \n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"♨ 경제\")\n",
    "\n",
    "a_links = soup.select('#section_economy > div.com_list > div > ul > li > a > strong')\n",
    "\n",
    "for a_link in a_links:\n",
    "    name = a_link.string\n",
    "    print(name.strip())\n",
    "    \n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"♨ 사회\")\n",
    "\n",
    "a_links = soup.select('#section_society > div.com_list > div > ul > li > a > strong')\n",
    "\n",
    "for a_link in a_links:\n",
    "    name = a_link.string\n",
    "    print(name.strip())\n",
    "    \n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"♨ 생활/문화\")\n",
    "\n",
    "a_links = soup.select('#section_life > div.com_list > div > ul > li > a > strong')\n",
    "\n",
    "for a_link in a_links:\n",
    "    name = a_link.string\n",
    "    print(name.strip())\n",
    "    \n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"♨ 세계\")\n",
    "\n",
    "a_links = soup.select('#section_world > div.com_list > div > ul > li > a > strong')\n",
    "\n",
    "for a_link in a_links:\n",
    "    name = a_link.string\n",
    "    print(name.strip())\n",
    "    \n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "print(\"♨ IT/과학\")\n",
    "\n",
    "a_links = soup.select('#section_it > div.com_list > div > ul > li > a > strong')\n",
    "\n",
    "for a_link in a_links:\n",
    "    name = a_link.string\n",
    "    print(name.strip())\n",
    "    \n",
    "print(\"--------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
